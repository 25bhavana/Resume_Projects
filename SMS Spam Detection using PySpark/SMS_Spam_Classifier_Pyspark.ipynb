{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgnR-a2uDVqc"
      },
      "source": [
        "### Initializing Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-27T06:27:32.995303Z",
          "start_time": "2020-06-27T06:27:28.591358Z"
        },
        "id": "3BpCkvJrDVqd"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName('Fraud detection').getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-27T06:27:34.455096Z",
          "start_time": "2020-06-27T06:27:32.997289Z"
        },
        "id": "SZWKxXz_DVqf",
        "outputId": "69334772-0106-48de-b84c-42a2458c7d75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- label: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sms = spark.read.csv(\"spam.csv\", header=True, inferSchema = True )\n",
        "\n",
        "sms.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-25T13:07:20.689440Z",
          "start_time": "2020-06-25T13:07:20.684455Z"
        },
        "id": "rJujYsQyDVqg"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-27T06:27:35.984275Z",
          "start_time": "2020-06-27T06:27:34.458086Z"
        },
        "id": "LjwzZunMDVqh",
        "outputId": "d75a7c59-8461-4385-d6d3-9b8fd5b520dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+-----+------+\n",
            "| id|                text|label|length|\n",
            "+---+--------------------+-----+------+\n",
            "|  1|Go until jurong p...|    0|   111|\n",
            "|  2|Ok lar... Joking ...|    0|    29|\n",
            "|  3|Free entry in 2 a...|    1|   155|\n",
            "|  4|U dun say so earl...|    0|    49|\n",
            "|  5|Nah I don't think...|    0|    61|\n",
            "|  6|FreeMsg Hey there...|    1|   147|\n",
            "|  7|Even my brother i...|    0|    77|\n",
            "|  8|As per your reque...|    0|   160|\n",
            "|  9|WINNER!! As a val...|    1|   157|\n",
            "| 10|Had your mobile 1...|    1|   154|\n",
            "| 11|I'm gonna be home...|    0|   109|\n",
            "| 12|SIX chances to wi...|    1|   136|\n",
            "| 13|URGENT! You have ...|    1|   155|\n",
            "| 14|I've been searchi...|    0|   196|\n",
            "| 15|I HAVE A DATE ON ...|    0|    35|\n",
            "| 16|XXXMobileMovieClu...|    1|   149|\n",
            "| 17|Oh k...i'm watchi...|    0|    26|\n",
            "| 18|Eh u remember how...|    0|    81|\n",
            "| 19|Fine if thatÔøΩÔøΩs t...|    0|    58|\n",
            "| 20|England v Macedon...|    1|   155|\n",
            "+---+--------------------+-----+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import length\n",
        "sms = sms.withColumn('length', length(sms['text']))\n",
        "sms.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-25T13:08:58.876488Z",
          "start_time": "2020-06-25T13:08:58.869512Z"
        },
        "id": "NXlPlAtpDVqi"
      },
      "source": [
        "<b>Next, I create a new column 'length' which signifies the length of the SMS.</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-27T06:27:36.694375Z",
          "start_time": "2020-06-27T06:27:35.986270Z"
        },
        "id": "G2dwroS0DVqj",
        "outputId": "01fca0fa-77a9-409a-aadc-546f1f47a04b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------------+\n",
            "|label|       avg(length)|\n",
            "+-----+------------------+\n",
            "| NULL|              74.5|\n",
            "|    1|138.45917001338688|\n",
            "|    0| 71.04167530582625|\n",
            "+-----+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sms.groupBy('label').avg('length').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmRBtIVGDVqj"
      },
      "source": [
        "<b>This is interesting, spam messages are twice as long as regular messages.</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-27T06:27:36.712327Z",
          "start_time": "2020-06-27T06:27:36.697369Z"
        },
        "id": "1iRUKUfgDVqk",
        "outputId": "debf76c1-291e-473c-e9b6-58cf433e3715",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- label: integer (nullable = true)\n",
            " |-- length: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sms.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We2UMAQEDVqk"
      },
      "source": [
        "### Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-27T06:27:36.925755Z",
          "start_time": "2020-06-27T06:27:36.717313Z"
        },
        "id": "Et_g9AkZDVqk"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import regexp_replace, lower\n",
        "\n",
        "wrangled = sms.withColumn('text', regexp_replace(sms.text, '[_():;,.!?\\\\-]', ' '))\n",
        "\n",
        "wrangled = wrangled.withColumn('text', regexp_replace(wrangled.text, '[0-9]', ' '))\n",
        "\n",
        "wrangled = wrangled.withColumn('text', regexp_replace(wrangled.text, ' +', ' '))\n",
        "\n",
        "wrangled = wrangled.withColumn('text', lower(wrangled['text']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZK3FOD2JDVql"
      },
      "source": [
        "<b>Above, we remove anything other that letters (eg- punctuations,numbers and symbols)</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-27T06:27:37.262854Z",
          "start_time": "2020-06-27T06:27:36.927750Z"
        },
        "id": "FILwZdp_DVql",
        "outputId": "fd713989-36ae-497e-f24e-e011ef68407d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "| NULL|    4|\n",
            "|    1|  747|\n",
            "|    0| 4823|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "wrangled.groupBy(\"label\").count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKbeGGJkDVql"
      },
      "source": [
        "<b>There are a total of 5574 SMS, of which only 747 have been labelled as spam.This dataset is highly imbalanced.As a classifier just predicting all the messages as not spam will get a accuracy of 87%.</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-27T06:27:37.444368Z",
          "start_time": "2020-06-27T06:27:37.264848Z"
        },
        "id": "5mzir3f8DVql",
        "outputId": "35d2ad88-b832-49a4-82f8-790b91b1f215",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+-----+------+\n",
            "| id|                text|label|length|\n",
            "+---+--------------------+-----+------+\n",
            "|  1|go until jurong p...|    0|   111|\n",
            "|  2|ok lar joking wif...|    0|    29|\n",
            "|  3|free entry in a w...|    1|   155|\n",
            "|  4|u dun say so earl...|    0|    49|\n",
            "|  5|nah i don't think...|    0|    61|\n",
            "|  6|freemsg hey there...|    1|   147|\n",
            "|  7|even my brother i...|    0|    77|\n",
            "|  8|as per your reque...|    0|   160|\n",
            "|  9|winner as a value...|    1|   157|\n",
            "| 10|had your mobile m...|    1|   154|\n",
            "| 11|i'm gonna be home...|    0|   109|\n",
            "| 12|six chances to wi...|    1|   136|\n",
            "| 13|urgent you have w...|    1|   155|\n",
            "| 14|i've been searchi...|    0|   196|\n",
            "| 15|i have a date on ...|    0|    35|\n",
            "| 16|xxxmobilemovieclu...|    1|   149|\n",
            "| 17|oh k i'm watching...|    0|    26|\n",
            "| 18|eh u remember how...|    0|    81|\n",
            "| 19|fine if thatÔøΩÔøΩs t...|    0|    58|\n",
            "| 20|england v macedon...|    1|   155|\n",
            "+---+--------------------+-----+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "wrangled.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIExU7KzDVqm"
      },
      "source": [
        "###  Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-27T06:27:37.709659Z",
          "start_time": "2020-06-27T06:27:37.446363Z"
        },
        "id": "MtoB8sTGDVqm"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "tokenizer = Tokenizer(inputCol='text', outputCol='words')\n",
        "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol='terms')\n",
        "vectorizer = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"raw_features\", vocabSize=10000)\n",
        "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
        "\n",
        "pipeline = Pipeline(stages=[tokenizer, remover, vectorizer, idf])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mHpv6tMDVqm"
      },
      "source": [
        "<b>First we tokenize the text into individual tokens,then remove stopwords.After that I perform hashing(hashing provides a fast and space-efficient way to map a huge number of words present in the SMS messages onto a smaller, finite number of values.At last I create a TF-IDF matrix which gives relatively higher importance to words that are rare across documents.<br>\n",
        "Next, I create a pipeline which wraps all of the above steps. </b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-27T06:27:39.482878Z",
          "start_time": "2020-06-27T06:27:37.712653Z"
        },
        "id": "WhHXA_XGDVqm"
      },
      "outputs": [],
      "source": [
        "pipeline_model = pipeline.fit(wrangled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-27T06:27:39.593564Z",
          "start_time": "2020-06-27T06:27:39.485855Z"
        },
        "id": "C44x-Jv_DVqn"
      },
      "outputs": [],
      "source": [
        "sms_transformed = pipeline_model.transform(wrangled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-27T06:27:39.630465Z",
          "start_time": "2020-06-27T06:27:39.595562Z"
        },
        "id": "Y-83eo52DVqn"
      },
      "outputs": [],
      "source": [
        "sms_train, sms_test = sms_transformed.randomSplit([0.7, 0.3], seed=13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPtIkNPIDVqo"
      },
      "source": [
        "### Class Weights (Handling Imbalanced Data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TG7mLTqDVqo"
      },
      "source": [
        "<b>Since where we have 87% positives (label == 0) in the dataset, so theoretically we want to \"under-sample\" the positive class. So that The logistic loss objective function should treat the negative class (label == 1) with higher weight.</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Inverse Class Frequency Method\n",
        "The Inverse Class Frequency method calculates class weights based on the number of samples in each class. For a binary classification problem with classes 0 and 1, the formula for calculating class weights is as follows:\n",
        "\n",
        "weight_0 = total_samples / (2 * class_0_samples)\n",
        "weight_1 = total_samples / (2 * class_1_samples)\n",
        "\n",
        "By dividing the total number of samples by twice the number of samples in each class, we ensure that the sum of the weights for both classes is the same, helping to balance the impact on the model.\n"
      ],
      "metadata": {
        "id": "KiPWUJ8RiCKL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-27T06:27:42.324010Z",
          "start_time": "2020-06-27T06:27:39.631465Z"
        },
        "id": "B1-i9wD0DVqp",
        "outputId": "4f8e83bf-1d8d-4211-939a-b80a7874f0e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of ones are 524\n",
            "Percentage of ones are 13.357124649502932\n",
            "The number of zeros are 3399.0\n"
          ]
        }
      ],
      "source": [
        "dataset_size=float(sms_train.select(\"label\").count())\n",
        "numPositives=sms_train.select(\"label\").where('label == 1').count()\n",
        "per_ones=(float(numPositives)/float(dataset_size))*100\n",
        "numNegatives=float(dataset_size-numPositives)\n",
        "print('The number of ones are {}'.format(numPositives))\n",
        "print('Percentage of ones are {}'.format(per_ones))\n",
        "print('The number of zeros are {}'.format(numNegatives))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-27T06:27:42.334348Z",
          "start_time": "2020-06-27T06:27:42.326989Z"
        },
        "id": "HWDmM0k0DVqr",
        "outputId": "ff04295e-1c4b-4087-efc2-dec3bddd61af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BalancingRatio = 0.8664287535049707\n"
          ]
        }
      ],
      "source": [
        "BalancingRatio= numNegatives/dataset_size\n",
        "print('BalancingRatio = {}'.format(BalancingRatio))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-27T06:27:43.329307Z",
          "start_time": "2020-06-27T06:27:42.337959Z"
        },
        "id": "PMpvNLJvDVqs",
        "outputId": "22326652-cc4f-4111-8ee6-bb96f9f443b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|classWeights       |label|features                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "+-------------------+-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|0.13357124649502927|0    |(8178,[7,13,24,52,69,72,266,527,649,684,918,1209,1251,2776,5381,7169],[3.035060615817463,3.19232559277408,3.6702205387270586,3.934699714099176,4.061699404860483,4.160139477673736,5.160311693528593,5.681608617161879,5.986990266713061,5.986990266713061,6.228152323529949,6.546606054648484,6.546606054648484,7.52743530766021,7.9329004157683745,7.9329004157683745])|\n",
            "|0.13357124649502927|0    |(8178,[20,45,78,236,401,1115],[3.4612616224048054,3.758513145872737,4.148710781850113,4.962485950198674,5.407171771460119,6.4288230189921])                                                                                                                                                                                                                              |\n",
            "|0.13357124649502927|0    |(8178,[97,271,848],[4.308559482792009,5.099687071712158,6.141140946540319])                                                                                                                                                                                                                                                                                              |\n",
            "|0.13357124649502927|0    |(8178,[383,761,1472],[5.407171771460119,6.061098238866783,6.680137447273006])                                                                                                                                                                                                                                                                                            |\n",
            "|0.13357124649502927|0    |(8178,[3,52,62,87,157,194,266,1140,1205,2353,3054,3642],[2.707153742055173,3.934699714099176,3.981656697186947,4.195230797485006,4.637063549764045,4.7758999946182605,5.160311693528593,6.546606054648484,6.546606054648484,7.239753235208429,7.52743530766021,7.52743530766021])                                                                                        |\n",
            "+-------------------+-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import when\n",
        "sms_train=sms_train.withColumn(\"classWeights\", when(sms_train.label == 1,BalancingRatio).otherwise(1-BalancingRatio))\n",
        "sms_train.select(\"classWeights\",\"label\",\"features\").show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-27T04:31:09.621735Z",
          "start_time": "2020-06-27T04:31:09.616746Z"
        },
        "id": "bH5Qt1x5DVqt"
      },
      "source": [
        "<b>Here we give a weight of ~0.87 to spam messages and ~0.13 to non spam messages.</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzMAhzqNDVqu"
      },
      "source": [
        "### Model Building and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-27T06:27:48.225206Z",
          "start_time": "2020-06-27T06:27:43.334291Z"
        },
        "id": "MJDGNizTDVqu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f646351-cbb6-4112-922d-429aeee9c250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression AUC: 0.9914022016146067\n",
            "Random Forest AUC: 0.9864418124510964\n",
            "GBT AUC: 0.9812190270283859\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "# Logistic Regression (already weighted)\n",
        "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", weightCol=\"classWeights\", maxIter=10)\n",
        "\n",
        "# Random Forest (supports weightCol)\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", weightCol=\"classWeights\", numTrees=100)\n",
        "\n",
        "# Gradient Boosted Tree (no weightCol support)\n",
        "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=100)\n",
        "\n",
        "# Drop rows with null labels before fitting the models\n",
        "sms_train_cleaned = sms_train.dropna(subset=[\"label\"])\n",
        "\n",
        "# Fit models\n",
        "lr_model = lr.fit(sms_train_cleaned)\n",
        "rf_model = rf.fit(sms_train_cleaned)\n",
        "gbt_model = gbt.fit(sms_train_cleaned.drop(\"classWeights\"))  # remove classWeights or it will error\n",
        "\n",
        "# Make predictions\n",
        "lr_pred = lr_model.transform(sms_test)\n",
        "rf_pred = rf_model.transform(sms_test)\n",
        "gbt_pred = gbt_model.transform(sms_test)\n",
        "\n",
        "# Drop rows with null labels and null raw predictions from prediction dataframes before evaluating\n",
        "lr_pred_cleaned = lr_pred.dropna(subset=[\"label\", \"rawPrediction\"])\n",
        "rf_pred_cleaned = rf_pred.dropna(subset=[\"label\", \"rawPrediction\"])\n",
        "gbt_pred_cleaned = gbt_pred.dropna(subset=[\"label\", \"rawPrediction\"])\n",
        "\n",
        "# Evaluate\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"label\")\n",
        "print(\"Logistic Regression AUC:\", evaluator.evaluate(lr_pred_cleaned))\n",
        "print(\"Random Forest AUC:\", evaluator.evaluate(rf_pred_cleaned))\n",
        "print(\"GBT AUC:\", evaluator.evaluate(gbt_pred_cleaned))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-27T06:27:50.003450Z",
          "start_time": "2020-06-27T06:27:48.227203Z"
        },
        "id": "aXWCPv2WDVqv"
      },
      "outputs": [],
      "source": [
        "def evaluate_metrics(prediction_df, model_name=\"Model\"):\n",
        "    total = prediction_df.count()\n",
        "    TP = prediction_df.filter('label = 1 AND prediction = 1').count()\n",
        "    TN = prediction_df.filter('label = 0 AND prediction = 0').count()\n",
        "    FP = prediction_df.filter('label = 0 AND prediction = 1').count()\n",
        "    FN = prediction_df.filter('label = 1 AND prediction = 0').count()\n",
        "\n",
        "    accuracy = (TP + TN) / total if total != 0 else 0\n",
        "    precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
        "    recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
        "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
        "\n",
        "    print(f\"üîç {model_name}\")\n",
        "    print(f\"Accuracy : {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall   : {recall:.4f}\")\n",
        "    print(f\"F1 Score : {f1:.4f}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    return {\n",
        "        \"Model\": model_name,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1 Score\": f1\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgOtFPSmDVqv"
      },
      "source": [
        "<b>Wow! we get a roc-auc score of 97% with our baseline model.But it is a fact that F1 score is a better evaluation metric than roc-auc when dealing with imbalanced datasets (see [here](https://www.kaggle.com/lct14558/imbalanced-data-why-you-should-not-use-roc-curve)),so we will consider F1 score as well.</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-27T06:27:51.326909Z",
          "start_time": "2020-06-27T06:27:50.008439Z"
        },
        "id": "CqngB5MjDVqv",
        "outputId": "360d216e-831e-4708-d015-a2f2264ab5b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Logistic Regression\n",
            "Accuracy : 0.9794\n",
            "Precision: 0.9897\n",
            "Recall   : 0.8610\n",
            "F1 Score : 0.9209\n",
            "------------------------------\n",
            "üîç Random Forest\n",
            "Accuracy : 0.9649\n",
            "Precision: 0.9882\n",
            "Recall   : 0.7534\n",
            "F1 Score : 0.8550\n",
            "------------------------------\n",
            "üîç Gradient Boosted Tree\n",
            "Accuracy : 0.9727\n",
            "Precision: 0.9590\n",
            "Recall   : 0.8386\n",
            "F1 Score : 0.8947\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression\n",
        "lr_metrics = evaluate_metrics(lr_pred, \"Logistic Regression\")\n",
        "\n",
        "# Random Forest\n",
        "rf_metrics = evaluate_metrics(rf_pred, \"Random Forest\")\n",
        "\n",
        "# GBT (no class weighting)\n",
        "gbt_metrics = evaluate_metrics(gbt_pred, \"Gradient Boosted Tree\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_results = [lr_metrics, rf_metrics, gbt_metrics]\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(all_results)\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3NI4FS1YMfF",
        "outputId": "fd0da565-f8ac-4814-bc4b-52170501ce67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   Model  Accuracy  Precision    Recall  F1 Score\n",
            "0    Logistic Regression  0.979406   0.989691  0.860987  0.920863\n",
            "1          Random Forest  0.964870   0.988235  0.753363  0.854962\n",
            "2  Gradient Boosted Tree  0.972744   0.958974  0.838565  0.894737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqcvKB63DVqw"
      },
      "source": [
        "<b>As you can see we achieved a roc-auc score of 97% but a F1 score of just 90%.With hyper parameter using Grid search I think we can achieve much better results!</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-WWjCmKDVqy"
      },
      "source": [
        "<b>To conclude after all the hyper parameter tuning we end up witha model with a roc-auc score of 98% and F1 score of 93%.<br>It is worth mentioning that without adding the class weights we will end up with a model with an F1 score of 0 as precision was 0 but a roc-auc score of nearly 100%.This is because of the highly imbalanced data the model blindly predicts all the messages to be not spam.So it is very important to address the problem of imbalanced datasets.  </b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocX4DSTlDVqy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}